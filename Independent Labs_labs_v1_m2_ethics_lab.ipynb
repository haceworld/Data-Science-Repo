{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "6ca4ecdb689e464bb101d9105d782fc7ce302962d26c8c5b6f403fcd2bd8be3b"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Hands-on Lab: Considerations for Data Professionals using GenAI\n\n**Estimated time needed:** 45 minutes \n\n## Overview  \n\nIn this lab, you will assess and reinforce your understanding of key principles related to the ethical deployment of generative AI, specifically focusing on transparency, fairness, responsibility, accountability, and reliability.  \n\nYou will be presented with scenarios, and you are expected to provide a solution for the question based on the scenario. To help you with the solutions, a hint is provided for each exercise. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Learning Objectives \n\nAfter completing this lab, you will be able to: \n\n - Maintain transparency and fairness in your AI system \n\n - Ensure accountability in the deployment of AI chatbot \n\n - Enhance the reliability of your AI model to ensure accurate product descriptions \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 1:  \n\nYou are developing a generative AI system that creates personalized content recommendations for users. The system seems to consistently recommend content that aligns with certain cultural and demographic biases.  \n\nUsers from diverse backgrounds are expressing concern about the lack of transparency and fairness in the recommendations.  \n\nHow do you maintain transparency and fairness in your AI system? \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<i>Type your response here</i>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for hint</summary>\nConsider steps like conducting a bias assessment, enhancing diversity in training data, implementing explainability features, and establishing a user feedback loop to ensure fairness and transparency in your AI system. \n</details>\n\n<details><summary>Click here for sample solution</summary>\nTo address this issue, you could implement the following steps: \n\n1. Conduct a thorough bias assessment to identify and understand the biases present in the training data and algorithms. \n2. Use specialized tools or metrics to measure and quantify biases in content recommendations. \n3. Enhance the diversity of your training data by including a broader range of cultural, demographic, and user behavior data. \n4. Ensure that the training data reflects the diversity of your user base to reduce biases. \n5. Implement explainability features to provide users with insights into why specific recommendations are made. \n6. Offer transparency by showing the key factors and attributes influencing the recommendations. \n7. Establish a user feedback loop where users can report biased recommendations or provide feedback on content relevance. \n8. Regularly analyze this feedback to iteratively improve the system's fairness. \n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": ">**Additional Information**\n\n>Some specialized tools that can be used to measure and quantify biases: \n\n>Holistic AI Library: This open-source library offers a range of metrics and mitigation strategies for various AI tasks, including content recommendation. It analyzes data for bias across different dimensions and provides visualizations for clear understanding. \n\n>Fairness 360: IBM&#39;s Fairness 360 toolkit provides various tools like Aequitas and What-If Tool to analyze bias in data sets, models, and decision-making processes. It offers metrics like statistical parity, differential odds ratio, and counterfactual fairness. IBM moved AI Fairness 360 to LF AI in July 2020. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 2  \n\nYour company has deployed a chatbot powered by generative AI to interact with customers. The chatbot occasionally generates responses that are inappropriate or offensive, leading to customer dissatisfaction. As the AI developer, how do you take responsibility for these incidents and ensure accountability in the deployment of the AI chatbot? \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<i>Type your response here</i>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for hint</summary>\nTo address responsibility and accountability, analyze errors, respond swiftly, continuously monitor for inappropriate responses, and communicate openly with stakeholders about corrective actions taken to improve the chatbot&#39;s behavior. \n</details>\n\n<details><summary>Click here for sample solution</summary>\nAddressing responsibility and accountability in this scenario involves the following steps: \n\n1. Conduct a detailed analysis of the inappropriate responses to identify patterns and root causes. \n2. Determine whether the issues stem from biased training data, algorithmic limitations, or other factors. \n3. Implement a mechanism to quickly identify and rectify inappropriate responses by updating the chatbot&#39;s training data or fine-tuning the model. \n4. Communicate openly with affected customers, acknowledge the issue, and assure them of prompt corrective actions. \n5. Set up continuous monitoring systems to detect and flag inappropriate responses in real-time. \n6. Implement alerts or human-in-the-loop mechanisms to intervene when the system generates potentially harmful content. \n7. Clearly communicate the steps taken to address the issue to both internal stakeholders and customers. \n8. Emphasize the commitment to continuous improvement and the responsible use of AI technology. \n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 3: \n\nYour company has developed a generative AI model that autonomously generates product descriptions for an e-commerce platform. However, users have reported instances where the generated descriptions contain inaccurate information, leading to customer confusion and dissatisfaction. How do you enhance the reliability of your AI model to ensure accurate product descriptions? \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<i>Type your response here</i>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for hint</summary>\nTo improve reliability, focus on quality assurance testing, use domain-specific training data, adopt an iterative model training approach, and integrate user feedback to iteratively correct errors and enhance the accuracy of the AI-generated product descriptions. \n</details>\n\n<details><summary>Click here for sample solution</summary>\nTo improve the reliability of the AI model in generating product descriptions, consider the following actions: \n\n1. Implement rigorous quality assurance testing to evaluate the accuracy of the generated product descriptions. \n2. Create a comprehensive testing data set that covers a wide range of products and scenarios to identify and address inaccuracies. \n3. Ensure that the AI model is trained on a diverse and extensive data set specific to the e-commerce domain. \n4. Include product information from reputable sources to enhance the model's understanding of accurate product details. \n5. Implement an iterative training approach to continuously update and improve the model based on user feedback and evolving product data. \n6. Regularly retrain the model to adapt to changes in the product catalog and user preferences. \n7. Encourage users to provide feedback on inaccurate product descriptions. \n8. Use this feedback to fine-tune the model, correct errors, and improve the overall reliability of the AI-generated content.  \n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Congratulations! You have completed the lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Dr. Pooja](https://www.linkedin.com/in/p-b28802262/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Other Contributors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log--!>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-14|0.1|Abhishek Gagneja|Initial Draft created| --!>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright Â© 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}